#!/usr/bin/env python3
"""
Simple Performance Analysis without pandas
CppMMO ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê°„ë‹¨ ë¶„ì„
"""
import json
import glob
import os
from datetime import datetime

def find_result_files():
    """ìµœê·¼ ê²°ê³¼ íŒŒì¼ë“¤ ì°¾ê¸°"""
    json_files = glob.glob('performance_results_*.json')
    csv_files = glob.glob('performance_test_*.csv')
    
    # ì‹œê°„ìˆœ ì •ë ¬
    json_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    csv_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    
    return json_files, csv_files

def analyze_json_results(json_files):
    """JSON ê²°ê³¼ íŒŒì¼ ë¶„ì„"""
    results = []
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                client_count = data.get('client_count', 0)
                final_stats = data.get('final_stats', {})
                overall_score = data.get('overall_score', 0)
                
                # ì²˜ë¦¬ëŸ‰ ë°ì´í„°
                throughput = final_stats.get('throughput', {})
                packets_per_sec = throughput.get('packets_per_sec', 0)
                
                # ì§€ì—°ì‹œê°„ ë°ì´í„°
                latency = final_stats.get('latency', {})
                avg_latency = latency.get('avg', 0)
                p95_latency = latency.get('p95', 0)
                
                # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
                system = final_stats.get('system_resources', {})
                cpu_usage = system.get('cpu_usage', 0)
                memory_usage = system.get('memory_usage', 0)
                
                # ì•ˆì •ì„±
                errors = final_stats.get('errors', {})
                error_rate = errors.get('error_rate_percent', 0)
                
                # ì—°ê²° ì„±ê³µë¥ 
                connections = final_stats.get('connections', {})
                connected = connections.get('connected', 0)
                connection_success_rate = (connected / client_count * 100) if client_count > 0 else 0
                
                results.append({
                    'client_count': client_count,
                    'packets_per_sec': packets_per_sec,
                    'avg_latency_ms': avg_latency,
                    'p95_latency_ms': p95_latency,
                    'cpu_usage_percent': cpu_usage,
                    'memory_usage_percent': memory_usage,
                    'error_rate_percent': error_rate,
                    'connection_success_rate': connection_success_rate,
                    'overall_score': overall_score,
                    'file': json_file
                })
                
        except Exception as e:
            print(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({json_file}): {e}")
    
    return results

def print_performance_summary(results):
    """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
    if not results:
        print("ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í´ë¼ì´ì–¸íŠ¸ ìˆ˜ë³„ë¡œ ì •ë ¬
    results.sort(key=lambda x: x['client_count'])
    
    print(f"\n{'='*100}")
    print(f"CppMMO ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*100}")
    print(f"ë¶„ì„ëœ í…ŒìŠ¤íŠ¸: {len(results)}ê°œ")
    print(f"í´ë¼ì´ì–¸íŠ¸ ìˆ˜ ë²”ìœ„: {results[0]['client_count']}ëª… ~ {results[-1]['client_count']}ëª…")
    print(f"{'='*100}")
    
    # í—¤ë” ì¶œë ¥
    print(f"{'í´ë¼ì´ì–¸íŠ¸ìˆ˜':>8} {'ì²˜ë¦¬ëŸ‰(pps)':>12} {'í‰ê· ì§€ì—°(ms)':>12} {'P95ì§€ì—°(ms)':>12} {'CPU(%)':>8} {'ë©”ëª¨ë¦¬(%)':>9} {'ì—°ê²°ë¥ (%)':>9} {'ì¢…í•©ì ìˆ˜':>8} {'ë“±ê¸‰':>4}")
    print(f"{'-'*100}")
    
    for result in results:
        # ë“±ê¸‰ ê³„ì‚°
        score = result['overall_score']
        if score >= 90:
            grade = "Sê¸‰"
        elif score >= 80:
            grade = "Aê¸‰"
        elif score >= 70:
            grade = "Bê¸‰"
        elif score >= 60:
            grade = "Cê¸‰"
        else:
            grade = "Dê¸‰"
        
        print(f"{result['client_count']:>8d} "
              f"{result['packets_per_sec']:>12.1f} "
              f"{result['avg_latency_ms']:>12.2f} "
              f"{result['p95_latency_ms']:>12.2f} "
              f"{result['cpu_usage_percent']:>8.1f} "
              f"{result['memory_usage_percent']:>9.1f} "
              f"{result['connection_success_rate']:>9.1f} "
              f"{result['overall_score']:>8.1f} "
              f"{grade:>4}")
    
    print(f"{'-'*100}")
    
    # ì„±ëŠ¥ ë¶„ì„
    print(f"\nğŸ“Š ì„±ëŠ¥ ë¶„ì„:")
    
    # ìµœê³  ì²˜ë¦¬ëŸ‰
    max_throughput = max(results, key=lambda x: x['packets_per_sec'])
    print(f"ìµœê³  ì²˜ë¦¬ëŸ‰: {max_throughput['client_count']}ëª…ì—ì„œ {max_throughput['packets_per_sec']:.1f} packets/sec")
    
    # ìµœì € ì§€ì—°ì‹œê°„
    min_latency = min(results, key=lambda x: x['p95_latency_ms'] if x['p95_latency_ms'] > 0 else float('inf'))
    if min_latency['p95_latency_ms'] > 0:
        print(f"ìµœì € P95 ì§€ì—°ì‹œê°„: {min_latency['client_count']}ëª…ì—ì„œ {min_latency['p95_latency_ms']:.2f}ms")
    
    # CPU 100% ë„ë‹¬ì 
    cpu_100_results = [r for r in results if r['cpu_usage_percent'] >= 99.0]
    if cpu_100_results:
        first_cpu_100 = min(cpu_100_results, key=lambda x: x['client_count'])
        print(f"CPU í•œê³„ì : {first_cpu_100['client_count']}ëª…ì—ì„œ CPU {first_cpu_100['cpu_usage_percent']:.1f}%")
    
    # ê¶Œì¥ ìµœëŒ€ í´ë¼ì´ì–¸íŠ¸ ìˆ˜
    stable_results = [r for r in results if 
                     r['error_rate_percent'] < 1.0 and 
                     r['connection_success_rate'] > 95.0 and
                     r['cpu_usage_percent'] < 90.0]
    
    if stable_results:
        max_stable = max(stable_results, key=lambda x: x['client_count'])
        print(f"ê¶Œì¥ ìµœëŒ€ í´ë¼ì´ì–¸íŠ¸: {max_stable['client_count']}ëª… (ì•ˆì •ì  ìš´ì˜ ê¸°ì¤€)")
    
    # ì„±ëŠ¥ ì €í•˜ ì‹œì‘ì 
    if len(results) >= 2:
        for i in range(1, len(results)):
            prev_score = results[i-1]['overall_score']
            curr_score = results[i]['overall_score']
            
            if prev_score - curr_score > 10:  # 10ì  ì´ìƒ ê°ì†Œ
                print(f"ì„±ëŠ¥ ì €í•˜ ì‹œì‘: {results[i-1]['client_count']}ëª… â†’ {results[i]['client_count']}ëª…ì—ì„œ ì ìˆ˜ {prev_score:.1f} â†’ {curr_score:.1f}")
                break
    
    print(f"\nğŸ’¡ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
    
    # CPUê°€ ë†’ì€ ê²½ìš°
    high_cpu_results = [r for r in results if r['cpu_usage_percent'] > 80]
    if high_cpu_results:
        print(f"- CPU ìµœì í™” í•„ìš”: {len(high_cpu_results)}ê°œ í…ŒìŠ¤íŠ¸ì—ì„œ CPU > 80%")
        print(f"  ê¶Œì¥: í”„ë¡œíŒŒì¼ë§, ì•Œê³ ë¦¬ì¦˜ ìµœì í™”, ë©€í‹°ìŠ¤ë ˆë”© ê°œì„ ")
    
    # ì§€ì—°ì‹œê°„ì´ ë†’ì€ ê²½ìš°
    high_latency_results = [r for r in results if r['p95_latency_ms'] > 100]
    if high_latency_results:
        print(f"- ì§€ì—°ì‹œê°„ ê°œì„  í•„ìš”: {len(high_latency_results)}ê°œ í…ŒìŠ¤íŠ¸ì—ì„œ P95 ì§€ì—°ì‹œê°„ > 100ms")
        print(f"  ê¶Œì¥: ë„¤íŠ¸ì›Œí¬ ë²„í¼ íŠœë‹, ì‘ë‹µ ì‹œê°„ ìµœì í™”")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ì€ ê²½ìš°
    high_memory_results = [r for r in results if r['memory_usage_percent'] > 70]
    if high_memory_results:
        print(f"- ë©”ëª¨ë¦¬ ìµœì í™” í•„ìš”: {len(high_memory_results)}ê°œ í…ŒìŠ¤íŠ¸ì—ì„œ ë©”ëª¨ë¦¬ > 70%")
        print(f"  ê¶Œì¥: ë©”ëª¨ë¦¬ í’€ ë„ì…, ë¶ˆí•„ìš”í•œ í• ë‹¹ ìµœì†Œí™”")

def main():
    print("CppMMO ì„œë²„ ì„±ëŠ¥ ë¶„ì„ (Simple Version)")
    
    json_files, csv_files = find_result_files()
    
    if not json_files:
        print("ë¶„ì„í•  ì„±ëŠ¥ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("python comprehensive_performance_test.py --scenario basic --clients 200")
        return
    
    print(f"ë°œê²¬ëœ ê²°ê³¼ íŒŒì¼: {len(json_files)}ê°œ")
    
    # JSON íŒŒì¼ ë¶„ì„
    results = analyze_json_results(json_files)
    
    # ìš”ì•½ ì¶œë ¥
    print_performance_summary(results)
    
    # ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f"performance_summary_{timestamp}.txt"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("CppMMO ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½\n")
        f.write(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("="*100 + "\n")
        
        f.write(f"ë¶„ì„ëœ í…ŒìŠ¤íŠ¸: {len(results)}ê°œ\n")
        if results:
            f.write(f"í´ë¼ì´ì–¸íŠ¸ ìˆ˜ ë²”ìœ„: {results[0]['client_count']}ëª… ~ {results[-1]['client_count']}ëª…\n")
        f.write("="*100 + "\n\n")
        
        # ìƒì„¸ ë°ì´í„°
        f.write("ìƒì„¸ ê²°ê³¼:\n")
        f.write(f"{'í´ë¼ì´ì–¸íŠ¸ìˆ˜':>8} {'ì²˜ë¦¬ëŸ‰(pps)':>12} {'í‰ê· ì§€ì—°(ms)':>12} {'P95ì§€ì—°(ms)':>12} {'CPU(%)':>8} {'ë©”ëª¨ë¦¬(%)':>9} {'ì—°ê²°ë¥ (%)':>9} {'ì¢…í•©ì ìˆ˜':>8}\n")
        f.write("-"*100 + "\n")
        
        for result in results:
            f.write(f"{result['client_count']:>8d} "
                  f"{result['packets_per_sec']:>12.1f} "
                  f"{result['avg_latency_ms']:>12.2f} "
                  f"{result['p95_latency_ms']:>12.2f} "
                  f"{result['cpu_usage_percent']:>8.1f} "
                  f"{result['memory_usage_percent']:>9.1f} "
                  f"{result['connection_success_rate']:>9.1f} "
                  f"{result['overall_score']:>8.1f}\n")
    
    print(f"\nğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸ê°€ {report_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()