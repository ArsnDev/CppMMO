#!/usr/bin/env python3
"""
CppMMO ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í†µí•© ìŠ¤í¬ë¦½íŠ¸
ì—¬ëŸ¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ í†µí•© ë¶„ì„í•©ë‹ˆë‹¤.
"""
import subprocess
import sys
import time
import json
import os
from datetime import datetime
import argparse

class PerformanceTestRunner:
    def __init__(self):
        self.results = {}
        self.test_start_time = None
        
    def check_server_status(self, host='localhost', port=8080):
        """ì„œë²„ ìƒíƒœ í™•ì¸"""
        import socket
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex((host, port))
            sock.close()
            return result == 0
        except Exception:
            return False
    
    def run_system_monitor_background(self, duration):
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„° ì‹¤í–‰"""
        print("ë°±ê·¸ë¼ìš´ë“œ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
        
        cmd = [sys.executable, 'system_monitor.py', '--duration', str(duration)]
        process = subprocess.Popen(cmd, 
                                 stdout=subprocess.PIPE, 
                                 stderr=subprocess.PIPE,
                                 universal_newlines=True)
        return process
    
    def run_comprehensive_test(self, scenario):
        """ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\n{'='*80}")
        print(f"ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘: {scenario.upper()} ì‹œë‚˜ë¦¬ì˜¤")
        print(f"{'='*80}")
        
        cmd = [sys.executable, 'comprehensive_performance_test.py', '--scenario', scenario]
        
        try:
            result = subprocess.run(cmd, 
                                  capture_output=True, 
                                  text=True, 
                                  timeout=3600)  # 1ì‹œê°„ íƒ€ì„ì•„ì›ƒ
            
            if result.returncode == 0:
                print(f"âœ… {scenario} ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
                return True, result.stdout, result.stderr
            else:
                print(f"âŒ {scenario} ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                print(f"ì˜¤ë¥˜: {result.stderr}")
                return False, result.stdout, result.stderr
                
        except subprocess.TimeoutExpired:
            print(f"â° {scenario} ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ íƒ€ì„ì•„ì›ƒ")
            return False, "", "Test timeout"
        except Exception as e:
            print(f"ğŸ’¥ {scenario} ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì˜ˆì™¸: {e}")
            return False, "", str(e)
    
    def run_specific_load_test(self, test_script, test_name):
        """íŠ¹ì • ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print(f"{test_name} ì‹¤í–‰ ì¤‘...")
        print(f"{'='*60}")
        
        cmd = [sys.executable, test_script]
        
        try:
            result = subprocess.run(cmd,
                                  capture_output=True,
                                  text=True,
                                  timeout=1800)  # 30ë¶„ íƒ€ì„ì•„ì›ƒ
            
            if result.returncode == 0:
                print(f"âœ… {test_name} ì™„ë£Œ")
                return True, result.stdout, result.stderr
            else:
                print(f"âŒ {test_name} ì‹¤íŒ¨")
                return False, result.stdout, result.stderr
                
        except subprocess.TimeoutExpired:
            print(f"â° {test_name} íƒ€ì„ì•„ì›ƒ")
            return False, "", "Test timeout"
        except Exception as e:
            print(f"ğŸ’¥ {test_name} ì˜ˆì™¸: {e}")
            return False, "", str(e)
    
    def analyze_result_files(self):
        """ìƒì„±ëœ ê²°ê³¼ íŒŒì¼ë“¤ ë¶„ì„"""
        result_files = {
            'performance_results': [],
            'csv_files': [],
            'system_monitor': [],
            'other_logs': []
        }
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ë“¤ ìŠ¤ìº”
        current_time = datetime.now()
        for filename in os.listdir('.'):
            # ìµœê·¼ 1ì‹œê°„ ë‚´ ìƒì„±ëœ íŒŒì¼ë§Œ ê³ ë ¤
            try:
                file_time = datetime.fromtimestamp(os.path.getmtime(filename))
                if (current_time - file_time).total_seconds() > 3600:
                    continue
            except:
                continue
            
            if filename.startswith('performance_results_') and filename.endswith('.json'):
                result_files['performance_results'].append(filename)
            elif filename.endswith('.csv'):
                if 'system_monitor' in filename:
                    result_files['system_monitor'].append(filename)
                else:
                    result_files['csv_files'].append(filename)
            elif filename.endswith('.log'):
                result_files['other_logs'].append(filename)
        
        return result_files
    
    def generate_combined_report(self, test_results, result_files):
        """í†µí•© ë¦¬í¬íŠ¸ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"comprehensive_test_report_{timestamp}.json"
        
        # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒŒì¼ë“¤ ì½ê¸°
        performance_data = {}
        for perf_file in result_files['performance_results']:
            try:
                with open(perf_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    scenario = data.get('scenario', 'unknown')
                    performance_data[scenario] = data
            except Exception as e:
                print(f"ê²°ê³¼ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ ({perf_file}): {e}")
        
        # í†µí•© ë¦¬í¬íŠ¸ ë°ì´í„°
        combined_report = {
            'test_execution_info': {
                'start_time': self.test_start_time.isoformat() if self.test_start_time else None,
                'end_time': datetime.now().isoformat(),
                'total_duration_minutes': (datetime.now() - self.test_start_time).total_seconds() / 60 if self.test_start_time else 0
            },
            'test_results': test_results,
            'performance_data': performance_data,
            'result_files': result_files,
            'summary': self.generate_test_summary(test_results, performance_data)
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(combined_report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“Š í†µí•© ë¦¬í¬íŠ¸ê°€ {report_filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì½˜ì†”ì— ìš”ì•½ ì¶œë ¥
        self.print_test_summary(combined_report['summary'])
        
        return report_filename
    
    def generate_test_summary(self, test_results, performance_data):
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ ìƒì„±"""
        summary = {
            'tests_executed': len(test_results),
            'tests_passed': sum(1 for result in test_results.values() if result['success']),
            'tests_failed': sum(1 for result in test_results.values() if not result['success']),
            'scenarios_tested': list(performance_data.keys()),
            'overall_performance': {}
        }
        
        # ì„±ëŠ¥ ë°ì´í„° ìš”ì•½
        if performance_data:
            all_scores = [data.get('overall_score', 0) for data in performance_data.values() if 'overall_score' in data]
            if all_scores:
                summary['overall_performance'] = {
                    'average_score': sum(all_scores) / len(all_scores),
                    'best_score': max(all_scores),
                    'worst_score': min(all_scores),
                    'scores_by_scenario': {scenario: data.get('overall_score', 0) 
                                         for scenario, data in performance_data.items()}
                }
        
        return summary
    
    def print_test_summary(self, summary):
        """í…ŒìŠ¤íŠ¸ ìš”ì•½ ì½˜ì†” ì¶œë ¥"""
        print(f"\n{'='*100}")
        print(f"CppMMO ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µí•© ê²°ê³¼")
        print(f"{'='*100}")
        
        print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í˜„í™©:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {summary['tests_executed']}")
        print(f"  ì„±ê³µ: {summary['tests_passed']} | ì‹¤íŒ¨: {summary['tests_failed']}")
        print(f"  ì„±ê³µë¥ : {summary['tests_passed'] / summary['tests_executed'] * 100:.1f}%")
        
        if summary['scenarios_tested']:
            print(f"\nğŸ¯ í…ŒìŠ¤íŠ¸ëœ ì‹œë‚˜ë¦¬ì˜¤:")
            for scenario in summary['scenarios_tested']:
                print(f"  - {scenario.upper()}")
        
        if summary['overall_performance']:
            perf = summary['overall_performance']
            print(f"\nğŸ† ì¢…í•© ì„±ëŠ¥ ì ìˆ˜:")
            print(f"  í‰ê·  ì ìˆ˜: {perf['average_score']:.1f}/100")
            print(f"  ìµœê³  ì ìˆ˜: {perf['best_score']:.1f}/100")
            print(f"  ìµœì € ì ìˆ˜: {perf['worst_score']:.1f}/100")
            
            print(f"\nğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ë³„ ì ìˆ˜:")
            for scenario, score in perf['scores_by_scenario'].items():
                if score >= 90:
                    grade = "ğŸ… Sê¸‰"
                elif score >= 80:
                    grade = "ğŸ¥ˆ Aê¸‰"
                elif score >= 70:
                    grade = "ğŸ¥‰ Bê¸‰"
                elif score >= 60:
                    grade = "âš ï¸ Cê¸‰"
                else:
                    grade = "âŒ Dê¸‰"
                
                print(f"  {scenario.upper()}: {score:.1f}/100 {grade}")
        
        print(f"\nğŸ’¡ ì¢…í•© í‰ê°€:")
        if summary['tests_failed'] == 0:
            if summary.get('overall_performance', {}).get('average_score', 0) >= 80:
                print("  ğŸ‰ ìš°ìˆ˜ - ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼, ë†’ì€ ì„±ëŠ¥ ì ìˆ˜")
            else:
                print("  âœ… ì–‘í˜¸ - ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼, ì„±ëŠ¥ ê°œì„  ì—¬ì§€ ìˆìŒ")
        else:
            print("  âš ï¸ ê°œì„  í•„ìš” - ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ë˜ëŠ” ì„±ëŠ¥ ì´ìŠˆ")
        
        print(f"{'='*100}")
    
    def run_all_tests(self, scenarios=None, include_load_tests=True):
        """ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.test_start_time = datetime.now()
        test_results = {}
        
        print(f"{'='*100}")
        print(f"CppMMO ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µí•© ì‹¤í–‰")
        print(f"ì‹œì‘ ì‹œê°„: {self.test_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*100}")
        
        # ì„œë²„ ìƒíƒœ í™•ì¸
        if not self.check_server_status():
            print("âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return
        
        print("âœ… ì„œë²„ ì—°ê²° í™•ì¸ë¨")
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
        if scenarios is None:
            scenarios = ['basic', 'stress']  # extremeì€ ì„ íƒì 
        
        # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œê°„ ì¶”ì •
        scenario_durations = {'basic': 2, 'stress': 5, 'extreme': 10}  # ë¶„ ë‹¨ìœ„
        estimated_time = sum(scenario_durations.get(s, 5) for s in scenarios)
        if include_load_tests:
            estimated_time += 10  # ì¶”ê°€ ë¶€í•˜ í…ŒìŠ¤íŠ¸
        
        print(f"ğŸ“… ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ {estimated_time}ë¶„")
        print(f"ğŸ”„ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: {', '.join(s.upper() for s in scenarios)}")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        total_duration = estimated_time * 60 + 120  # ì—¬ìœ  ì‹œê°„ 2ë¶„ ì¶”ê°€
        monitor_process = self.run_system_monitor_background(total_duration)
        
        time.sleep(3)  # ëª¨ë‹ˆí„°ë§ ì•ˆì •í™” ëŒ€ê¸°
        
        try:
            # 1. ì¢…í•© ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            for scenario in scenarios:
                print(f"\nâ³ {scenario.upper()} ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ì¤‘...")
                time.sleep(2)  # ì„œë²„ ì•ˆì •í™”
                
                success, stdout, stderr = self.run_comprehensive_test(scenario)
                test_results[f'comprehensive_{scenario}'] = {
                    'success': success,
                    'stdout': stdout[:1000] if stdout else "",  # ê¸¸ì´ ì œí•œ
                    'stderr': stderr[:500] if stderr else "",
                    'scenario': scenario
                }
                
                if success:
                    print(f"âœ… {scenario.upper()} ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ")
                else:
                    print(f"âŒ {scenario.upper()} ì‹œë‚˜ë¦¬ì˜¤ ì‹¤íŒ¨")
                
                # ì‹œë‚˜ë¦¬ì˜¤ ê°„ íœ´ì‹
                if scenario != scenarios[-1]:
                    print("ğŸ’¤ ë‹¤ìŒ í…ŒìŠ¤íŠ¸ê¹Œì§€ 30ì´ˆ ëŒ€ê¸°...")
                    time.sleep(30)
            
            # 2. ì¶”ê°€ ë¶€í•˜ í…ŒìŠ¤íŠ¸ (ì„ íƒì )
            if include_load_tests:
                load_tests = [
                    ('movement_load_test.py', 'ì‹¤ì‹œê°„ ì´ë™ ë¶€í•˜ í…ŒìŠ¤íŠ¸'),
                    ('no_auth_stress_test.py', 'ì¸ì¦ ìš°íšŒ ë¶€í•˜ í…ŒìŠ¤íŠ¸')
                ]
                
                for script, name in load_tests:
                    if os.path.exists(script):
                        print(f"\nğŸ’¤ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ë¥¼ ìœ„í•´ 60ì´ˆ ëŒ€ê¸°...")
                        time.sleep(60)
                        
                        success, stdout, stderr = self.run_specific_load_test(script, name)
                        test_results[script.replace('.py', '')] = {
                            'success': success,
                            'stdout': stdout[:1000] if stdout else "",
                            'stderr': stderr[:500] if stderr else "",
                            'test_name': name
                        }
            
        except KeyboardInterrupt:
            print("\nâ›” ì‚¬ìš©ìì— ì˜í•´ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        finally:
            # ì‹œìŠ¤í…œ ëª¨ë‹ˆí„° í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
            if monitor_process and monitor_process.poll() is None:
                print("\nğŸ“Š ë°±ê·¸ë¼ìš´ë“œ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ ì¤‘...")
                monitor_process.terminate()
                try:
                    monitor_process.wait(timeout=10)
                except subprocess.TimeoutExpired:
                    monitor_process.kill()
        
        # ê²°ê³¼ íŒŒì¼ ë¶„ì„
        print("\nğŸ“ ê²°ê³¼ íŒŒì¼ ë¶„ì„ ì¤‘...")
        result_files = self.analyze_result_files()
        
        # í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
        print("\nğŸ“‹ í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        report_file = self.generate_combined_report(test_results, result_files)
        
        print(f"\nğŸŠ ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“Š ìƒì„¸ ê²°ê³¼ëŠ” {report_file}ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        return test_results, result_files

def main():
    parser = argparse.ArgumentParser(description='CppMMO ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µí•© ì‹¤í–‰')
    parser.add_argument('--scenarios', '-s', 
                        nargs='+',
                        choices=['basic', 'stress', 'extreme'],
                        default=['basic', 'stress'],
                        help='ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤')
    parser.add_argument('--no-load-tests', 
                        action='store_true',
                        help='ì¶”ê°€ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì œì™¸')
    parser.add_argument('--quick', '-q',
                        action='store_true',
                        help='ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (basic ì‹œë‚˜ë¦¬ì˜¤ë§Œ)')
    
    args = parser.parse_args()
    
    if args.quick:
        scenarios = ['basic']
        include_load_tests = False
    else:
        scenarios = args.scenarios
        include_load_tests = not args.no_load_tests
    
    print("CppMMO ì„œë²„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ì‹¤í–‰ ì „ì— ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
    print("1. CppMMO ì„œë²„ê°€ localhost:8080ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€")
    print("2. í…ŒìŠ¤íŠ¸ ì¤‘ ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìµœì†Œí™”í•  ê²ƒ")
    print("3. ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ì´ ìˆëŠ”ì§€ (ê²°ê³¼ íŒŒì¼ìš©)")
    
    response = input("\nì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆë‚˜ìš”? (y/N): ").strip().lower()
    if response != 'y':
        print("í…ŒìŠ¤íŠ¸ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
    
    runner = PerformanceTestRunner()
    runner.run_all_tests(scenarios, include_load_tests)

if __name__ == "__main__":
    main()